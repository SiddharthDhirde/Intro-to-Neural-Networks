{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd16312b",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb537f0",
   "metadata": {},
   "source": [
    "![Multi-Layer Perceptron (MLP)](./public/mlp.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392dc643",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "<img src=\"./public/neuron_model.jpeg\" alt=\"derivate\" />\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01043eb8",
   "metadata": {},
   "source": [
    "The Multilayer Perceptron (MLP) is a type of feedforward artificial neural network that consists of multiple layers of nodes, also known as neurons. Here's a breakdown:\n",
    "\n",
    "- **Architecture**: An MLP typically consists of an input layer, one or more hidden layers, and an output layer. Each layer is composed of multiple neurons, and each neuron in one layer is connected to every neuron in the adjacent layers.\n",
    "\n",
    "- **Activation Function**: Neurons in each layer (except the input layer) apply an activation function to their input to introduce non-linearity into the network. Common activation functions include sigmoid, tanh, ReLU, and softmax.\n",
    "\n",
    "- **Feedforward Operation**: During the feedforward operation, the input data is passed through the network layer by layer. The output of each layer serves as the input to the next layer, and this process continues until the output layer is reached, producing the final prediction.\n",
    "\n",
    "- **Training**: MLPs are trained using supervised learning techniques such as backpropagation and gradient descent. During training, the network adjusts its weights and biases iteratively to minimize a loss function, typically based on the discrepancy between predicted and actual outputs.\n",
    "\n",
    "- **Applications**: MLPs are used in various applications, including classification, regression, pattern recognition, and function approximation. They have been successfully applied in areas such as image recognition, natural language processing, and financial forecasting.\n",
    "\n",
    "MLPs are versatile and powerful models capable of learning complex patterns in data, making them one of the fundamental building blocks of deep learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4df33fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654536be",
   "metadata": {},
   "source": [
    "#### Explanation of `random.uniform(-1,1)`\n",
    "\n",
    "The `random.uniform()` function in Python's `random` module generates random floating-point numbers within a specified range. Here's a breakdown:\n",
    "\n",
    "- **Function**: `random.uniform()`\n",
    "- **Parameters**: The function takes two parameters: `a` and `b`, representing the lower and upper bounds of the range from which random numbers will be generated.\n",
    "- **Range**: The function generates random floating-point numbers uniformly distributed between `a` and `b`, inclusive of `a` but exclusive of `b`.\n",
    "- **Example**: `random.uniform(-1,1)` generates random numbers between -1 (inclusive) and 1 (exclusive), meaning the numbers can be any value within the interval [-1, 1), including -1 but not including 1.\n",
    "\n",
    "This function is commonly used in various applications, including generating initial weights for neural networks and implementing various statistical simulations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f17bca87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5524266492994823"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.uniform(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08d9e56f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.5833145357090717,\n",
       " -0.7951883277173355,\n",
       " -0.4454581786447185,\n",
       " -0.30053593352795205,\n",
       " -0.38859778135412104]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[random.uniform(-1,1) for _ in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a3ef13",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2329bcb2",
   "metadata": {},
   "source": [
    "### `__call__` Method\n",
    "\n",
    "The `__call__` method in Python is a special method that allows instances of a class to be called as if they were functions. Here's a breakdown:\n",
    "\n",
    "- **Usage**: The `__call__` method is invoked when an instance of a class is used with function-call syntax, i.e., `instance()`.\n",
    "  \n",
    "- **Functionality**: The purpose of the `__call__` method is to define what happens when an instance of the class is called. It allows the object to behave like a function, executing custom logic defined within the method.\n",
    "\n",
    "- **Flexibility**: By implementing the `__call__` method in a class, you can customize the behavior of instances and make them callable, enabling them to perform specific actions when invoked.\n",
    "\n",
    "- **Example**: Suppose you have a class named `MyFunction` with a `__call__` method defined. When you create an instance of `MyFunction` and call it with parentheses, the `__call__` method will be executed, allowing you to define custom behavior for the instance.\n",
    "\n",
    "- **Applications**: The `__call__` method is commonly used in various scenarios, such as creating callable objects, implementing function-like behavior for classes, and defining function decorators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95cf2690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# eg\n",
    "class Multiplier:\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return x * self.factor\n",
    "\n",
    "# Create an instance of Multiplier with a factor of 2\n",
    "double = Multiplier(2)\n",
    "\n",
    "# Call the instance as if it were a function\n",
    "result = double(5)  # This will multiply 5 by 2\n",
    "print(result)  # Output: 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d9ac5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a614454c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edeab38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7e06d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    # nin - no. of inputs\n",
    "    def __init__(self, nin):\n",
    "        self.w = [random.uniform(-1,1) for _ in range(nin)]\n",
    "        self.b = np.random.uniform(-1,1)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        # (w * x) + b\n",
    "        zip()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
